 ğŸ“° Article Processing System

A simple yet powerful FIFO (First In, First Out) article processing system that reads JSON articles, queues them through RabbitMQ, and stores them in MongoDB. Built with love using Node.js for developers who need reliable article data processing[1][2].

 What This Does:

Imagine you have hundreds of article JSON files sitting in a folder, and you need to process them one by one in the exact order they were created, then store them safely in a database. That's exactly what this system does!

**The Journey of an Article:**
1. ğŸ“ **JSON files** containing article data sit in the `articles/` folder
2. ğŸš€ **Producer** reads these files and sends each article to a message queue
3. ğŸ“¬ **RabbitMQ** ensures articles are processed in perfect FIFO order
4. ğŸ”„ **Consumer** picks up each article one by one
5. ğŸ’¾ **MongoDB** stores the processed articles safely
6. âœ… **Verification** confirms everything worked perfectly

## ğŸ› ï¸ Technology Stack

### **Node.js** - The Heart of Our System
We chose Node.js because it's perfect for I/O intensive operations like reading files and handling database connections. Its asynchronous nature means we can handle multiple articles efficiently without blocking operations.

### **RabbitMQ** - The Traffic Controller
Think of RabbitMQ as a smart postal service. It takes our articles and delivers them to the consumer in the exact order they were sent. No article gets lost, and if something goes wrong, it can retry delivery. The management UI at `http://localhost:15672` lets you peek into what's happening.

### **MongoDB** - The Safe Storage
MongoDB stores our articles as documents, which is perfect since our articles are already in JSON format. No complex table relationships needed - just simple, fast document storage that scales beautifully.

### **Docker** - The Easy Setup
Instead of installing RabbitMQ and MongoDB manually (which can be a nightmare), we use Docker containers. One command and everything is running perfectly.

## ğŸ“ Project Structure

```
article-processor/
â”œâ”€â”€ ğŸ“„ package.json          # Project dependencies and scripts
â”œâ”€â”€ ğŸ³ docker-compose.yml    # Container setup for RabbitMQ & MongoDB
â”œâ”€â”€ ğŸš€ producer.js           # Reads JSON files and queues articles
â”œâ”€â”€ ğŸ”„ consumer.js           # Processes queued articles to MongoDB
â”œâ”€â”€ ğŸ” verify-mongodb.js     # Checks if articles are stored correctly
â”œâ”€â”€ ğŸ“Š queue-monitor.js      # Monitors RabbitMQ queue status
â”œâ”€â”€ ğŸ“ articles/             # Drop your JSON files here
â”‚   â”œâ”€â”€ 60895087.json
â”‚   â”œâ”€â”€ 60946141.json
â”‚   â””â”€â”€ ... (all your article files)
â””â”€â”€ ğŸ“– README.md             # You're reading this!
```

## ğŸš€ Quick Start Guide

### **Step 1: Get Everything Ready**
```bash
# Clone or create the project folder
mkdir article-processor && cd article-processor

# Install the magic
npm install
```

### **Step 2: Start the Infrastructure**
```bash
# This starts RabbitMQ and MongoDB in Docker containers
docker-compose up -d

# Check if they're running (you should see 2 containers)
docker ps
```

### **Step 3: Add Your Articles**
Drop all your JSON article files into the `articles/` folder. The system will process them in alphabetical order (which maintains FIFO if your files are named chronologically).

### **Step 4: Start Processing**

**Terminal 1 - Start the Consumer (the worker):**
```bash
npm run consumer
```
You'll see: `ğŸš€ Consumer started. Waiting for articles...`

**Terminal 2 - Start the Producer (the feeder):**
```bash
npm run producer
```
Watch as it reads your files and sends articles to the queue!

### **Step 5: Verify Everything Worked**
```bash
# Check MongoDB storage
npm run verify

# Monitor RabbitMQ queue
npm run monitor
```

## ğŸ”§ Available Commands

| Command | What It Does |
|---------|-------------|
| `npm run producer` | Reads JSON files and queues articles |
| `npm run consumer` | Processes queued articles to MongoDB |
| `npm run verify` | Shows what's stored in MongoDB |
| `npm run monitor` | Checks RabbitMQ queue status |

## ğŸŒ Web Interfaces

- **RabbitMQ Management**: http://localhost:15672 (guest/guest)
  - See your queues, messages, and consumers in real-time
- **MongoDB**: mongodb://localhost:27017/articles_db
  - Connect with MongoDB Compass or any MongoDB client

## ğŸ” How to Know It's Working

### **Good Signs:**
- âœ… Consumer shows: `âœ… Saved to MongoDB: [article-id] - [title]`
- âœ… Producer shows: `âœ… Published: [article-id] - [title]`
- âœ… RabbitMQ UI shows your queue with 1 consumer
- âœ… MongoDB verification shows your articles

### **If Something's Wrong:**
- âŒ Check Docker containers: `docker ps`
- âŒ Check RabbitMQ: http://localhost:15672
- âŒ Run verification: `npm run verify`
- âŒ Monitor queue: `npm run monitor`

## ğŸ¯ FIFO Processing Explained

**Why FIFO Matters:**
If you have articles from different time periods, you want to process them in chronological order. Our system ensures:

1. **Producer** reads files in sorted order
2. **RabbitMQ** maintains message order with `prefetch(1)`
3. **Consumer** processes one article at a time
4. **MongoDB** stores them with processing timestamps

## ğŸ›¡ï¸ Error Handling

The system is built to be robust:
- **Duplicate Prevention**: Won't store the same article twice
- **Connection Recovery**: Handles database/queue disconnections
- **Message Persistence**: Articles survive system restarts
- **Graceful Shutdown**: Clean exit with Ctrl+C

## ğŸ”§ Customization

### **Change Database Name:**
Edit the MongoDB URL in `consumer.js`:
```javascript
await mongoose.connect('mongodb://localhost:27017/your_database_name');
```

### **Modify Article Schema:**
Update the schema in `consumer.js` to match your article structure.

### **Adjust Processing Speed:**
Add delays in the consumer for slower processing:
```javascript
await new Promise(resolve => setTimeout(resolve, 1000)); // 1 second delay
```

## ğŸ› Troubleshooting

### **"Queue is Empty" but Articles are in MongoDB**
This is actually **good news**! It means your system is working perfectly. The consumer is processing articles faster than they accumulate in the queue.

### **No Articles in MongoDB**
1. Check if consumer is running
2. Verify MongoDB connection
3. Run `npm run verify` to check database

### **RabbitMQ Connection Issues**
1. Ensure Docker containers are running: `docker ps`
2. Check RabbitMQ logs: `docker logs rabbitmq`

## ğŸ‰ Success Story

When everything works, you'll see a beautiful flow:
1. ğŸ“ JSON files â†’ ğŸš€ Producer â†’ ğŸ“¬ RabbitMQ â†’ ğŸ”„ Consumer â†’ ğŸ’¾ MongoDB
2. Your articles processed in perfect order
3. Zero data loss
4. Complete audit trail

Built with â¤ï¸ for reliable article processing. Happy coding! ğŸš€

---